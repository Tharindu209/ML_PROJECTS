{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "# from tqdm import tqdm\n",
    "import librosa\n",
    "from librosa.feature import mfcc\n",
    "from IPython.display import display, clear_output\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score , accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"/Users/tharindudamruwan/Desktop/ML and AI for DS/Intellihack/Notebooks/config.json\")\n",
    "data_para = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/tharindudamruwan/Desktop/ML and AI for DS/Intellihack/Songs/WavFile/Power',\n",
       " '/Users/tharindudamruwan/Desktop/ML and AI for DS/Intellihack/Songs/WavFile/Sorrow',\n",
       " '/Users/tharindudamruwan/Desktop/ML and AI for DS/Intellihack/Songs/WavFile/Romance',\n",
       " '/Users/tharindudamruwan/Desktop/ML and AI for DS/Intellihack/Songs/WavFile/Calm',\n",
       " '/Users/tharindudamruwan/Desktop/ML and AI for DS/Intellihack/Songs/WavFile/Joy']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_path = '/Users/tharindudamruwan/Desktop/ML and AI for DS/Intellihack/Songs/WavFile'\n",
    "file_path = [os.path.join(genre_path,x) for x in os.listdir(genre_path)]\n",
    "genres = [x for x in os.listdir(genre_path)]\n",
    "file_path.remove('/Users/tharindudamruwan/Desktop/ML and AI for DS/Intellihack/Songs/WavFile/.DS_Store')\n",
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_paths = []\n",
    "for i in tqdm(file_path):\n",
    "    for j in os.listdir(i):\n",
    "        file = os.path.join(i,j)\n",
    "        audio_paths.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_mfccs(path):\n",
    "    audio, sr = librosa.load(path)\n",
    "    frames = librosa.util.frame(audio, frame_length=sr*3, hop_length=sr*3)\n",
    "    frame_mfccs = []\n",
    "    for i in range(frames.shape[1]):\n",
    "        mfccs = mfcc(y=frames[:,i],sr=sr,n_mfcc=13,hop_length=512,n_fft=2048)\n",
    "        frame_mfccs.append(mfccs)\n",
    "    return frame_mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "for path in tqdm(audio_paths):\n",
    "    display(path)\n",
    "    genre = path.split('/')[8]\n",
    "    try:\n",
    "        fmccs = get_frame_mfccs(path)\n",
    "        clear_output(wait=True)\n",
    "        for frame in fmccs:\n",
    "            data.append(frame)\n",
    "            labels.append(genre)\n",
    "    except Exception:\n",
    "        pass\n",
    "print(audio_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(data) == len(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape(data,shape=(26,65)):\n",
    "    assert data.shape == (13,130) , f\"The Data shape should be (13,130) but got {data.shape}\"\n",
    "    data = data.reshape(shape)\n",
    "    data = np.expand_dims(data,axis=-1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = np.array([reshape(x) for x in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lbenc = LabelEncoder()\n",
    "labels = lbenc.fit_transform(labels)\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = lbenc.classes_\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_val,y_train,y_val = train_test_split(processed_data,labels,test_size=data_para['config'][0]['test_size'],\n",
    "                                               shuffle=data_para['config'][0]['shuffle'],random_state=data_para['config'][0]['random_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import InputLayer , Conv2D , AveragePooling2D , GlobalAvgPool2D , Dense\n",
    "import tensorflow as tf \n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    InputLayer(input_shape=(26,65,1)),\n",
    "    Conv2D(512,(3),padding='valid',activation='relu'),\n",
    "    Conv2D(256,(3),padding='valid',activation='relu'),\n",
    "    AveragePooling2D(pool_size=(3),strides=(2),padding='same'),\n",
    "    Conv2D(256,(3),padding='valid',activation='relu'),\n",
    "    AveragePooling2D(pool_size=(3),strides=(2),padding='same'),\n",
    "    Conv2D(256,(4),padding='valid',activation='relu'),\n",
    "    GlobalAvgPool2D(),\n",
    "    Dense(128,activation='relu'),\n",
    "    Dense(64,activation='relu'),\n",
    "    Dense(5,activation='softmax')\n",
    "])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "             loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "             metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train,y_train,batch_size=data_para['config'][0]['batch_size'],epochs=data_para['config'][0]['epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = np.arange(0,10)\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epochs,history.history['loss'],color='r')\n",
    "plt.title('Model loss (sparse categorical crossentropy)')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.tight_layout()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epochs,history.history['accuracy'],color='g')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_val)\n",
    "preds = []\n",
    "for i in pred:\n",
    "    out = np.argmax(i)\n",
    "    preds.append(out)\n",
    "f1score = f1_score(y_val,preds,average='micro')\n",
    "accuracy = accuracy_score(y_val,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The Test Accuracy is {accuracy} \\n The F1 Score is {f1score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('final_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_val,preds)\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation=45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "fmt = 'd'\n",
    "thresh = cm.max() / 2.\n",
    "for i, j in np.ndindex(cm.shape):\n",
    "    plt.text(j, i, format(cm[i, j], fmt),\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
